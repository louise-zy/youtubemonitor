#!/usr/bin/env python3
"""
YouTube RSSç›‘æ§æ¨¡å—
ä½¿ç”¨RSSè®¢é˜…ç›‘æ§YouTubeé¢‘é“æ›´æ–°ï¼Œæ— éœ€APIå¯†é’¥
"""

import os
import json
import time
import logging
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Sequence
import sqlite3
from dataclasses import dataclass
import hashlib
import re
from utils.dingtalk import DingTalkClient
from utils.ai import AIContentProcessor
from urllib.parse import parse_qs, urlparse
from http.cookiejar import MozillaCookieJar

# å­—å¹•æå–ç›¸å…³
try:
    import yt_dlp
    YT_DLP_AVAILABLE = True
except ImportError:
    YT_DLP_AVAILABLE = False
    logging.warning("yt-dlpåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install yt-dlp")

# AI APIç›¸å…³
try:
    import openai
    AI_API_AVAILABLE = True
except ImportError:
    AI_API_AVAILABLE = False
    logging.warning("OpenAIåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")

# youtube_transcript_api ç›¸å…³
try:
    from youtube_transcript_api import (  # type: ignore
        YouTubeTranscriptApi,
        TranscriptsDisabled,
        NoTranscriptFound,
    )
    YT_TRANSCRIPT_API_AVAILABLE = True
except ImportError:
    YT_TRANSCRIPT_API_AVAILABLE = False
    logging.warning("youtube-transcript-apiåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install youtube-transcript-api")

@dataclass
class YouTubeChannel:
    """YouTubeé¢‘é“ä¿¡æ¯"""
    name: str
    channel_id: str
    rss_url: str
    description: str
    last_video_id: str = ""
    last_check: str = ""
    last_update: str = ""

@dataclass
class VideoInfo:
    """è§†é¢‘ä¿¡æ¯"""
    video_id: str
    title: str
    description: str
    published_at: str
    channel_name: str
    video_url: str
    transcript: str = ""
    summary: str = ""
    outline: str = ""

class YouTubeRSSParser:
    """YouTube RSSè§£æå™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def get_channel_id_from_url(self, channel_url: str) -> Optional[str]:
        """ä»é¢‘é“URLæå–é¢‘é“ID"""
        try:
            # ç¡®ä¿URLæœ‰åè®®å‰ç¼€
            if not channel_url.startswith(('http://', 'https://')):
                channel_url = 'https://' + channel_url
            
            if '/channel/' in channel_url:
                return channel_url.split('/channel/')[-1].split('/')[0]
            elif '/@' in channel_url:
                # éœ€è¦é€šè¿‡é¡µé¢è§£æè·å–é¢‘é“ID
                return self._get_channel_id_from_handle(channel_url)
            elif '/c/' in channel_url or '/user/' in channel_url:
                # éœ€è¦é€šè¿‡é¡µé¢è§£æè·å–é¢‘é“ID
                return self._get_channel_id_from_custom_url(channel_url)
        except Exception as e:
            logging.error(f"æå–é¢‘é“IDå¤±è´¥: {e}")
        return None
    
    def _get_channel_id_from_handle(self, channel_url: str) -> Optional[str]:
        """ä»@handleæ ¼å¼çš„URLè·å–é¢‘é“ID"""
        try:
            # ç¡®ä¿URLæœ‰åè®®å‰ç¼€
            if not channel_url.startswith(('http://', 'https://')):
                channel_url = 'https://' + channel_url
            
            logging.info(f"æ­£åœ¨è·å–é¢‘é“ID: {channel_url}")
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = self.session.get(channel_url, timeout=30, headers=headers)
            logging.info(f"HTTPçŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = response.text
                logging.info(f"é¡µé¢å†…å®¹é•¿åº¦: {len(content)}")
                
                # æŸ¥æ‰¾é¡µé¢ä¸­çš„é¢‘é“ID - å°è¯•å¤šç§æ¨¡å¼
                import re
                
                # æ¨¡å¼1: "channelId":"UCxxxxxx"
                match = re.search(r'"channelId":"(UC[a-zA-Z0-9_-]+)"', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼1): {channel_id}")
                    return channel_id
                
                # æ¨¡å¼2: "externalId":"UCxxxxxx"
                match = re.search(r'"externalId":"(UC[a-zA-Z0-9_-]+)"', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼2): {channel_id}")
                    return channel_id
                
                # æ¨¡å¼3: channel/UCxxxxxx
                match = re.search(r'/channel/(UC[a-zA-Z0-9_-]+)', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼3): {channel_id}")
                    return channel_id
                
                # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè®°å½•éƒ¨åˆ†é¡µé¢å†…å®¹ç”¨äºè°ƒè¯•
                logging.warning("æœªæ‰¾åˆ°é¢‘é“IDï¼Œé¡µé¢å†…å®¹ç‰‡æ®µ:")
                logging.warning(content[:500] + "..." if len(content) > 500 else content)
                
            else:
                logging.error(f"HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            logging.error(f"ä»handleè·å–é¢‘é“IDå¤±è´¥: {e}")
        return None
    
    def _get_channel_id_from_custom_url(self, channel_url: str) -> Optional[str]:
        """ä»è‡ªå®šä¹‰URLè·å–é¢‘é“ID"""
        try:
            # ç¡®ä¿URLæœ‰åè®®å‰ç¼€
            if not channel_url.startswith(('http://', 'https://')):
                channel_url = 'https://' + channel_url
            
            logging.info(f"æ­£åœ¨è·å–è‡ªå®šä¹‰URLé¢‘é“ID: {channel_url}")
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = self.session.get(channel_url, timeout=30, headers=headers)
            logging.info(f"HTTPçŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = response.text
                logging.info(f"é¡µé¢å†…å®¹é•¿åº¦: {len(content)}")
                
                # æŸ¥æ‰¾é¢‘é“ID - å°è¯•å¤šç§æ¨¡å¼
                import re
                
                # æ¨¡å¼1: "channelId":"UCxxxxxx"
                match = re.search(r'"channelId":"(UC[a-zA-Z0-9_-]+)"', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼1): {channel_id}")
                    return channel_id
                
                # æ¨¡å¼2: "externalId":"UCxxxxxx"
                match = re.search(r'"externalId":"(UC[a-zA-Z0-9_-]+)"', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼2): {channel_id}")
                    return channel_id
                
                # æ¨¡å¼3: channel/UCxxxxxx
                match = re.search(r'/channel/(UC[a-zA-Z0-9_-]+)', content)
                if match:
                    channel_id = match.group(1)
                    logging.info(f"æ‰¾åˆ°é¢‘é“ID (æ¨¡å¼3): {channel_id}")
                    return channel_id
                
                # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè®°å½•éƒ¨åˆ†é¡µé¢å†…å®¹ç”¨äºè°ƒè¯•
                logging.warning("æœªæ‰¾åˆ°é¢‘é“IDï¼Œé¡µé¢å†…å®¹ç‰‡æ®µ:")
                logging.warning(content[:500] + "..." if len(content) > 500 else content)
                
            else:
                logging.error(f"HTTPè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            logging.error(f"ä»è‡ªå®šä¹‰URLè·å–é¢‘é“IDå¤±è´¥: {e}")
        return None
    
    def get_rss_url(self, channel_id: str) -> str:
        """ç”ŸæˆRSSè®¢é˜…URL"""
        return f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
    
    def parse_rss_feed(self, rss_url: str) -> List[VideoInfo]:
        """è§£æRSSè®¢é˜…æº"""
        try:
            response = self.session.get(rss_url, timeout=30)
            response.raise_for_status()
            
            root = ET.fromstring(response.content)
            
            # å®šä¹‰å‘½åç©ºé—´
            namespaces = {
                'atom': 'http://www.w3.org/2005/Atom',
                'yt': 'http://www.youtube.com/xml/schemas/2015',
                'media': 'http://search.yahoo.com/mrss/'
            }
            
            videos = []
            channel_name = ""
            
            # è·å–é¢‘é“åç§°
            title_elem = root.find('atom:title', namespaces)
            if title_elem is not None:
                channel_name = title_elem.text
            
            # è§£æè§†é¢‘æ¡ç›®
            for entry in root.findall('atom:entry', namespaces):
                try:
                    video_id_elem = entry.find('yt:videoId', namespaces)
                    title_elem = entry.find('atom:title', namespaces)
                    published_elem = entry.find('atom:published', namespaces)
                    description_elem = entry.find('media:group/media:description', namespaces)
                    link_elem = entry.find('atom:link', namespaces)
                    
                    if video_id_elem is not None and title_elem is not None:
                        video_id = video_id_elem.text
                        title = title_elem.text
                        published_at = published_elem.text if published_elem is not None else ""
                        description = description_elem.text if description_elem is not None else ""
                        video_url = f"https://www.youtube.com/watch?v={video_id}"
                        
                        video_info = VideoInfo(
                            video_id=video_id,
                            title=title,
                            description=description,
                            published_at=published_at,
                            channel_name=channel_name,
                            video_url=video_url
                        )
                        videos.append(video_info)
                        
                except Exception as e:
                    logging.error(f"è§£æè§†é¢‘æ¡ç›®å¤±è´¥: {e}")
                    continue
            
            return videos
            
        except Exception as e:
            logging.error(f"è§£æRSSè®¢é˜…å¤±è´¥: {e}")
            return []

class TranscriptExtractor:
    """å­—å¹•æå–å™¨ï¼Œè´Ÿè´£æœ€å¤§åŒ–å¯ç”¨å­—å¹•çš„è·å–æˆåŠŸç‡"""

    DEFAULT_HEADERS = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
            "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
    }

    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.enabled = self.config.get("enabled", True)
        self.allow_auto = self.config.get("allow_automatic_subtitles", True)
        self.prefer_manual = self.config.get("prefer_manual_subtitles", True)
        self.max_retries = max(1, int(self.config.get("max_retries", 2)))
        self.retry_wait = max(1, int(self.config.get("retry_wait_seconds", 3)))
        self.request_timeout = int(self.config.get("request_timeout", 30))
        self.proxy = self.config.get("proxy") or None
        self.cookie_file = self._prepare_cookie_file(self.config.get("cookie_file"))
        self.languages = self._expand_langs(self.config.get("languages", ["zh", "en"]))
        self.use_transcript_api = self.config.get("use_transcript_api", True)
        self.transcript_api_translate_to = self.config.get("transcript_api_auto_translate_to")
        self.transcript_api_languages = self._expand_langs(
            self.config.get("transcript_api_preferred_languages", self.languages)
        )

        self.session = requests.Session()
        self.session.headers.update(self.DEFAULT_HEADERS)
        extra_headers = self.config.get("http_headers") or {}
        if isinstance(extra_headers, dict):
            self.session.headers.update(extra_headers)
        if self.proxy:
            self.session.proxies.update({
                "http": self.proxy,
                "https": self.proxy
            })

        if self.cookie_file:
            self._load_cookies(self.cookie_file)

        if not YT_DLP_AVAILABLE:
            logging.warning("yt-dlpä¸å¯ç”¨ï¼Œæ— æ³•æå–å­—å¹•")

    def extract_transcript(self, video_id: str, languages: Optional[List[str]] = None) -> str:
        """æå–è§†é¢‘å­—å¹•"""
        preferred_langs = self._expand_langs(languages or self.languages)

        if not self.enabled:
            return ""

        tracks_sources: List[Dict[str, List[Dict]]] = []
        if YT_DLP_AVAILABLE:
            logging.info(f"å°è¯•ä½¿ç”¨ yt-dlp è·å–å­—å¹•: {video_id}")
            info = self._fetch_metadata_with_yt_dlp(video_id, preferred_langs)
            if info:
                manual_tracks = info.get("subtitles") or {}
                auto_tracks = info.get("automatic_captions") or {}
                if manual_tracks and self.prefer_manual:
                    tracks_sources.append(manual_tracks)
                if auto_tracks and self.allow_auto:
                    tracks_sources.append(auto_tracks)
                if not tracks_sources and manual_tracks:
                    tracks_sources.append(manual_tracks)
                if not tracks_sources and auto_tracks:
                    tracks_sources.append(auto_tracks)
            else:
                logging.warning(f"yt-dlp æœªèƒ½è·å–åˆ°å…ƒæ•°æ®: {video_id}")

        for tracks in tracks_sources:
            text = self._extract_from_tracks(tracks, preferred_langs)
            if text:
                logging.info(f"yt-dlp æˆåŠŸæå–å­—å¹•ï¼Œé•¿åº¦: {len(text)}")
                return text

        logging.info(f"yt-dlp æå–å¤±è´¥æˆ–æ— å­—å¹•ï¼Œå°è¯• fallback æ–¹æ¡ˆ: {video_id}")
        return self._fallback_transcript_api(video_id, preferred_langs)

    def _fetch_metadata_with_yt_dlp(self, video_id: str, languages: List[str]) -> Optional[Dict]:
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        ydl_opts = {
            "skip_download": True,
            "quiet": True,
            "nocheckcertificate": True,
            "user_agent": self.session.headers.get("User-Agent"),
            "http_headers": dict(self.session.headers),
            "subtitlesformat": "vtt",
            "subtitleslangs": languages,
            "writesubtitles": True,
            "writeautomaticsub": True,
        }
        if self.cookie_file:
            ydl_opts["cookiefile"] = self.cookie_file
        if self.proxy:
            ydl_opts["proxy"] = self.proxy

        for attempt in range(self.max_retries):
            try:
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    return ydl.extract_info(video_url, download=False)
            except Exception as exc:  # noqa: BLE001
                logging.warning(
                    "yt-dlpå­—å¹•å…ƒæ•°æ®è·å–å¤±è´¥ï¼ˆç¬¬%sæ¬¡å°è¯•ï¼‰: %s", attempt + 1, exc
                )
                if attempt + 1 < self.max_retries:
                    time.sleep(self.retry_wait)
        return None

    def _extract_from_tracks(self, tracks: Dict[str, List[Dict]], preferred_langs: List[str]) -> str:
        if not tracks:
            return ""

        chosen_lang = self._choose_language(list(tracks.keys()), preferred_langs)
        if not chosen_lang:
            chosen_lang = next(iter(tracks.keys()), None)
            if not chosen_lang:
                return ""

        formats = tracks.get(chosen_lang, [])
        chosen_fmt = self._select_format(formats)
        if not chosen_fmt:
            return ""

        text = self._download_subtitle_file(chosen_fmt.get("url"))
        if not text:
            return ""

        return self._normalize_subtitle_text(text, chosen_fmt.get("ext"))

    def _download_subtitle_file(self, url: Optional[str]) -> str:
        if not url:
            return ""
        cleaned_url = self._strip_range_param(url)

        for attempt in range(self.max_retries):
            try:
                resp = self.session.get(cleaned_url, timeout=self.request_timeout)
                resp.raise_for_status()
                text = resp.text
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºHTMLé¡µé¢ï¼ˆåçˆ¬è™«æ‹¦æˆªï¼‰
                if text.lstrip().startswith("<!DOCTYPE html") or "<html" in text.lower():
                    logging.warning(
                        "ä¸‹è½½çš„å†…å®¹ç–‘ä¼¼HTMLé¡µé¢è€Œéå­—å¹•ï¼ˆç¬¬%sæ¬¡å°è¯•ï¼‰ï¼Œå¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆª", 
                        attempt + 1
                    )
                    if attempt + 1 < self.max_retries:
                        time.sleep(self.retry_wait)
                    continue

                if text.lstrip().startswith("#EXTM3U"):
                    merged = self._merge_m3u_playlist(text, cleaned_url)
                    if merged:
                        text = merged
                return text
            except Exception as exc:  # noqa: BLE001
                logging.warning(
                    "å­—å¹•ä¸‹è½½å¤±è´¥ï¼ˆç¬¬%sæ¬¡å°è¯•ï¼‰: %s", attempt + 1, exc
                )
                if attempt + 1 < self.max_retries:
                    time.sleep(self.retry_wait)
        return ""

    def _normalize_subtitle_text(self, text: str, ext: Optional[str]) -> str:
        stripped = text.lstrip()
        if stripped.startswith("WEBVTT") or (ext and ext.lower() == "vtt"):
            return self._parse_vtt_to_text(text)
        if ext and ext.lower() == "srt":
            return self._parse_srt_to_text(text)
        return self._parse_vtt_to_text(text)
    
    def _expand_langs(self, languages: Sequence[str]) -> List[str]:
        base = [l.lower() for l in languages]
        zh_variants = ["zh", "zh-hans", "zh-hant", "zh-cn", "zh-tw"]
        en_variants = ["en", "en-us", "en-uk"]
        expanded = []
        for l in base:
            if l.startswith("zh"):
                expanded.extend(zh_variants)
            elif l.startswith("en"):
                expanded.extend(en_variants)
            else:
                expanded.append(l)
        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen, result = set(), []
        for l in expanded:
            if l not in seen:
                seen.add(l)
                result.append(l)
        return result

    def _choose_language(self, available: List[str], preferred: List[str]) -> Optional[str]:
        av_lower = {a.lower(): a for a in available}
        # ç²¾ç¡®åŒ¹é…
        for p in preferred:
            if p in av_lower:
                return av_lower[p]
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆzh/zh-å¼€å¤´ï¼‰
        for p in preferred:
            prefix = p.split("-")[0]
            for a in available:
                if a.lower().split("-")[0] == prefix:
                    return a
        return None

    def _strip_range_param(self, url: str) -> str:
        from urllib.parse import urlsplit, parse_qsl, urlencode, urlunsplit
        s = urlsplit(url)
        qs = [(k, v) for k, v in parse_qsl(s.query, keep_blank_values=True) if k.lower() != "range"]
        return urlunsplit((s.scheme, s.netloc, s.path, urlencode(qs, doseq=True), s.fragment))

    def _merge_m3u_playlist(self, m3u_text: str, base_url: str) -> str:
        from urllib.parse import urljoin
        segment_urls = []
        for line in m3u_text.splitlines():
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            segment_urls.append(urljoin(base_url, line))
        segments = []
        for u in segment_urls:
            u2 = self._strip_range_param(u)
            try:
                r = self.session.get(u2, timeout=self.request_timeout)
                if r.ok:
                    segments.append(r.text)
            except Exception:
                continue
        # åˆå¹¶å¹¶ç§»é™¤é‡å¤çš„ WEBVTT å¤´
        combined = []
        for idx, t in enumerate(segments):
            lines = t.splitlines()
            if lines and lines[0].strip().upper().startswith("WEBVTT"):
                lines = lines[1:]
            combined.extend(lines)
        return "\n".join(combined)

    def _parse_vtt_to_text(self, vtt: str) -> str:
        lines = []
        for ln in vtt.splitlines():
            s = ln.strip()
            if not s:
                continue
            if s.upper().startswith("WEBVTT") or s.upper().startswith("NOTE"):
                continue
            if "-->" in s:
                continue
            if s.isdigit():
                continue
            lines.append(s)
        return " ".join(lines)

    def _parse_srt_to_text(self, srt: str) -> str:
        lines = []
        for ln in srt.splitlines():
            s = ln.strip()
            if not s:
                continue
            if "-->" in s:
                continue
            if s.isdigit():
                continue
            lines.append(s)
        return " ".join(lines)

    def _select_format(self, formats: List[Dict]) -> Optional[Dict]:
        if not formats:
            return None
        for preferred_ext in ("vtt", "srt"):
            for fmt in formats:
                if fmt.get("ext") == preferred_ext and fmt.get("url"):
                    return fmt
        for fmt in formats:
            if fmt.get("url"):
                return fmt
        return None

    def _fallback_transcript_api(self, video_id: str, preferred_langs: List[str]) -> str:
        if not self.use_transcript_api or not YT_TRANSCRIPT_API_AVAILABLE:
            return ""

        try:
            # å®ä¾‹åŒ– API å¯¹è±¡ (v1.2.3+ ç‰ˆæœ¬éœ€è¦)
            yt_api = YouTubeTranscriptApi()
            transcript_list = yt_api.list(video_id)
        except (TranscriptsDisabled, NoTranscriptFound):
            return ""
        except Exception as exc:  # noqa: BLE001
            logging.warning("youtube_transcript_apiä¸å¯ç”¨: %s", exc)
            return ""

        # ä¼˜å…ˆæŒ‰åå¥½è¯­è¨€æŸ¥æ‰¾
        search_languages = preferred_langs or self.transcript_api_languages
        for lang in search_languages:
            try:
                transcript = transcript_list.find_transcript([lang])
                # fetch() è¿”å› FetchedTranscript å¯¹è±¡ï¼Œéœ€è¦è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                fetched = transcript.fetch()
                # å…¼å®¹ä¸åŒç‰ˆæœ¬ï¼Œå¦‚æœè¿”å›çš„æ˜¯å¯¹è±¡åˆ™è°ƒç”¨ to_raw_data()
                if hasattr(fetched, 'to_raw_data'):
                    data = fetched.to_raw_data()
                else:
                    data = fetched
                text = self._entries_to_text(data)
                if text:
                    return text
            except Exception:
                continue

        # è‡ªåŠ¨ç¿»è¯‘å…œåº•
        target_lang = self.transcript_api_translate_to
        if target_lang:
            for transcript in transcript_list:
                if not getattr(transcript, "is_translatable", False):
                    continue
                try:
                    translated = transcript.translate(target_lang)
                    fetched = translated.fetch()
                    if hasattr(fetched, 'to_raw_data'):
                        data = fetched.to_raw_data()
                    else:
                        data = fetched
                    text = self._entries_to_text(data)
                    if text:
                        return text
                except Exception:
                    continue

        # æœ€åå°è¯•åˆ—è¡¨ä¸­çš„ä»»æ„å­—å¹•
        for transcript in transcript_list:
            try:
                fetched = transcript.fetch()
                if hasattr(fetched, 'to_raw_data'):
                    data = fetched.to_raw_data()
                else:
                    data = fetched
                text = self._entries_to_text(data)
                if text:
                    return text
            except Exception:
                continue

        return ""

    def _entries_to_text(self, entries: List[Dict]) -> str:
        return " ".join(e.get("text", "").strip() for e in entries if e.get("text"))

    def _prepare_cookie_file(self, cookie_file: Optional[str]) -> Optional[str]:
        if not cookie_file:
            return None
        path = os.path.abspath(cookie_file)
        if os.path.exists(path):
            return path
        logging.warning("æŒ‡å®šçš„cookieæ–‡ä»¶ä¸å­˜åœ¨: %s", path)
        return None

    def _load_cookies(self, cookie_file: str) -> None:
        try:
            jar = MozillaCookieJar(cookie_file)
            jar.load(ignore_discard=True, ignore_expires=True)
            self.session.cookies.update(jar)
        except Exception as exc:  # noqa: BLE001
            logging.warning("åŠ è½½cookieæ–‡ä»¶å¤±è´¥: %s", exc)

class DingTalkNotifier(DingTalkClient):
    """é’‰é’‰æ¨é€é€šçŸ¥å™¨"""
    
    def send_message(self, videos: List[VideoInfo], at_all: bool = False, at_mobiles: List[str] = None) -> bool:
        """
        å‘é€é’‰é’‰æ¶ˆæ¯
        
        Args:
            videos: è§†é¢‘ä¿¡æ¯åˆ—è¡¨
            at_all: æ˜¯å¦@æ‰€æœ‰äºº
            at_mobiles: è¦@çš„æ‰‹æœºå·åˆ—è¡¨
            
        Returns:
            bool: å‘é€æ˜¯å¦æˆåŠŸ
        """
        if not videos:
            return True
            
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        content = "## ğŸ“º YouTubeæ–°è§†é¢‘æ¨é€\n\n"
        MAX_BYTES = 18000  # é’‰é’‰é™åˆ¶20000å­—èŠ‚ï¼Œé¢„ç•™ä¸€äº›ç©ºé—´
        
        for video in videos:
            video_content = ""
            video_content += f"### {video.title}\n\n"
            video_content += f"**ğŸ¬ é¢‘é“ï¼š** {video.channel_name}\n\n"
            video_content += f"**â° å‘å¸ƒæ—¶é—´ï¼š** {video.published_at}\n\n"
            video_content += f"**ğŸ”— è§†é¢‘é“¾æ¥ï¼š** [ç‚¹å‡»è§‚çœ‹]({video.video_url})\n\n"
            
            if video.summary:
                video_content += f"**ğŸ“ AIæ‘˜è¦ï¼š**\n\n{video.summary}\n\n"
            
            video_content += "---\n\n"
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé•¿åº¦é™åˆ¶
            if len((content + video_content).encode('utf-8')) > MAX_BYTES:
                # å¦‚æœå•ä¸ªè§†é¢‘å†…å®¹å°±è¶…é•¿ï¼Œéœ€è¦æˆªæ–­æ‘˜è¦
                if len(video_content.encode('utf-8')) > MAX_BYTES:
                    limit = MAX_BYTES - len(content.encode('utf-8')) - 100
                    if limit > 500:
                        video_content = video_content[:limit] + "...\n\n(å†…å®¹è¿‡é•¿å·²æˆªæ–­)"
                    else:
                        logging.warning("æ¶ˆæ¯å†…å®¹è¿‡é•¿ï¼Œè·³è¿‡éƒ¨åˆ†è§†é¢‘æ¨é€")
                        continue
                else:
                    # å¦‚æœåŠ ä¸Šè¿™ä¸ªè§†é¢‘è¶…é•¿ï¼Œå°±å…ˆå‘é€å½“å‰çš„ï¼Œå‰©ä¸‹çš„ä¸‹æ¬¡å¾ªç¯ï¼ˆè¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥åˆ†æ‰¹å‘é€ä¼šæ›´å¤æ‚ï¼Œ
                    # æš‚æ—¶å…ˆæˆªæ–­ï¼Œå› ä¸ºmax_videos_per_check=1é€šå¸¸ä¸ä¼šè§¦å‘ï¼‰
                    logging.warning("æ¶ˆæ¯å†…å®¹æ¥è¿‘ä¸Šé™ï¼Œåœæ­¢æ·»åŠ æ›´å¤šè§†é¢‘")
                    break
            
            content += video_content
        
        return self.send_markdown("YouTubeæ–°è§†é¢‘æ¨é€", content, at_all, at_mobiles)

class YouTubeDatabaseManager:
    """YouTubeæ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "youtube_rss_monitor.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # åˆ›å»ºé¢‘é“è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS youtube_channels (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL,
                        channel_id TEXT UNIQUE NOT NULL,
                        rss_url TEXT NOT NULL,
                        description TEXT,
                        last_video_id TEXT,
                        last_check TEXT,
                        last_update TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # åˆ›å»ºè§†é¢‘è¡¨
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS youtube_videos (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        video_id TEXT UNIQUE NOT NULL,
                        title TEXT NOT NULL,
                        description TEXT,
                        published_at TEXT,
                        channel_name TEXT,
                        video_url TEXT,
                        transcript TEXT,
                        summary TEXT,
                        outline TEXT,
                        processed_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                conn.commit()
                logging.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
                
        except Exception as e:
            logging.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def save_channel(self, channel: YouTubeChannel):
        """ä¿å­˜é¢‘é“ä¿¡æ¯"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT OR REPLACE INTO youtube_channels 
                    (name, channel_id, rss_url, description, last_video_id, last_check, last_update)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    channel.name, channel.channel_id, channel.rss_url,
                    channel.description, channel.last_video_id,
                    channel.last_check, channel.last_update
                ))
                conn.commit()
        except Exception as e:
            logging.error(f"ä¿å­˜é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
    
    def get_channel(self, channel_id: str) -> Optional[YouTubeChannel]:
        """è·å–é¢‘é“ä¿¡æ¯"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT name, channel_id, rss_url, description, 
                           last_video_id, last_check, last_update
                    FROM youtube_channels WHERE channel_id = ?
                ''', (channel_id,))
                
                row = cursor.fetchone()
                if row:
                    return YouTubeChannel(
                        name=row[0], channel_id=row[1], rss_url=row[2],
                        description=row[3], last_video_id=row[4],
                        last_check=row[5], last_update=row[6]
                    )
        except Exception as e:
            logging.error(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
        return None
    
    def save_video(self, video: VideoInfo):
        """ä¿å­˜è§†é¢‘ä¿¡æ¯"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    INSERT OR REPLACE INTO youtube_videos 
                    (video_id, title, description, published_at, channel_name, 
                     video_url, transcript, summary, outline)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    video.video_id, video.title, video.description,
                    video.published_at, video.channel_name, video.video_url,
                    video.transcript, video.summary, video.outline
                ))
                conn.commit()
        except Exception as e:
            logging.error(f"ä¿å­˜è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
    
    def is_first_run(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œï¼ˆæ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•è§†é¢‘è®°å½•ï¼‰"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM youtube_videos")
                count = cursor.fetchone()[0]
                return count == 0
        except Exception as e:
            logging.error(f"æ£€æŸ¥é¦–æ¬¡è¿è¡ŒçŠ¶æ€å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤è®¤ä¸ºæ˜¯é¦–æ¬¡è¿è¡Œ
    
    def is_channel_first_run(self, channel_name: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šé¢‘é“æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œï¼ˆè¯¥é¢‘é“æ²¡æœ‰ä»»ä½•è§†é¢‘è®°å½•ï¼Œæˆ–é¢‘é“æœªè®°å½•æœ€è¿‘è§†é¢‘ï¼‰"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                # æ¡ä»¶1ï¼šè§†é¢‘è¡¨ä¸­æ²¡æœ‰è¯¥é¢‘é“çš„è§†é¢‘
                cursor.execute("SELECT COUNT(*) FROM youtube_videos WHERE channel_name = ?", (channel_name,))
                count = cursor.fetchone()[0]
                if count > 0:
                    return False

                # æ¡ä»¶2ï¼šé¢‘é“è¡¨å­˜åœ¨è¯¥é¢‘é“ï¼Œä½†å°šæœªè®°å½•last_video_idï¼ˆè¯´æ˜è¿˜æ²¡æˆåŠŸå¤„ç†è¿‡è§†é¢‘ï¼‰
                cursor.execute("SELECT last_video_id FROM youtube_channels WHERE name = ?", (channel_name,))
                row = cursor.fetchone()
                if row is None:
                    # é¢‘é“è®°å½•ä¸å­˜åœ¨ï¼Œè§†ä¸ºé¦–æ¬¡è¿è¡Œ
                    return True
                last_video_id = row[0]
                return (last_video_id is None) or (last_video_id == "")

        except Exception as e:
            logging.error(f"æ£€æŸ¥é¢‘é“é¦–æ¬¡è¿è¡ŒçŠ¶æ€å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶é»˜è®¤è®¤ä¸ºæ˜¯é¦–æ¬¡è¿è¡Œ
    
    def get_latest_video_published_at_for_channel(self, channel_name: str) -> Optional[str]:
        """è·å–æŒ‡å®šé¢‘é“åœ¨æ•°æ®åº“ä¸­æœ€æ–°çš„è§†é¢‘å‘å¸ƒæ—¶é—´"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT published_at FROM youtube_videos 
                    WHERE channel_name = ? 
                    ORDER BY published_at DESC 
                    LIMIT 1
                """, (channel_name,))
                result = cursor.fetchone()
                return result[0] if result else None
        except Exception as e:
            logging.error(f"è·å–é¢‘é“æœ€æ–°è§†é¢‘å‘å¸ƒæ—¶é—´å¤±è´¥: {e}")
            return None
    
    def video_exists(self, video_id: str) -> bool:
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å­˜åœ¨"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('SELECT 1 FROM youtube_videos WHERE video_id = ?', (video_id,))
                return cursor.fetchone() is not None
        except Exception as e:
            logging.error(f"æ£€æŸ¥è§†é¢‘å­˜åœ¨æ€§å¤±è´¥: {e}")
            return False

class YouTubeRSSMonitor:
    """YouTube RSSç›‘æ§å™¨ä¸»ç±»"""
    
    def __init__(self, config_path: str = "youtube_rss_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.rss_parser = YouTubeRSSParser()
        self.subtitle_config = self._build_subtitle_config()
        self.transcript_extractor = TranscriptExtractor(self.subtitle_config)
        self.db_manager = YouTubeDatabaseManager()
        
        # åˆå§‹åŒ–AIå¤„ç†å™¨
        self.ai_processor = None
        if self.config.get('deepseek_api_key'):
            self.ai_processor = AIContentProcessor(
                api_key=self.config['deepseek_api_key'],
                base_url=self.config.get('ai_base_url', 'https://api.deepseek.com'),
                model=self.config.get('ai_model', 'deepseek-chat'),
                options=self.config.get('ai_options')
            )
        
        # åˆå§‹åŒ–é’‰é’‰æ¨é€å™¨
        self.dingtalk_notifier = None
        dingtalk_config = self.config.get('dingtalk', {})
        if dingtalk_config.get('enabled') and dingtalk_config.get('webhook_url'):
            self.dingtalk_notifier = DingTalkNotifier(
                webhook_url=dingtalk_config['webhook_url'],
                secret=dingtalk_config.get('secret')
            )
    
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–"""
        config = self._get_default_config()
        
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config.update(json.load(f))
            except Exception as e:
                logging.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # ç¯å¢ƒå˜é‡è¦†ç›–
        if os.environ.get('DEEPSEEK_API_KEY'):
            config['deepseek_api_key'] = os.environ['DEEPSEEK_API_KEY']
        if os.environ.get('AI_BASE_URL'):
            config['ai_base_url'] = os.environ['AI_BASE_URL']
        if os.environ.get('AI_MODEL'):
            config['ai_model'] = os.environ['AI_MODEL']
            
        if os.environ.get('DINGTALK_WEBHOOK'):
            if 'dingtalk' not in config:
                config['dingtalk'] = {'enabled': True}
            config['dingtalk']['webhook_url'] = os.environ['DINGTALK_WEBHOOK']
            config['dingtalk']['enabled'] = True
            
        if os.environ.get('DINGTALK_SECRET'):
            if 'dingtalk' not in config:
                config['dingtalk'] = {'enabled': True}
            config['dingtalk']['secret'] = os.environ['DINGTALK_SECRET']

        return config
    
    def _create_sample_config(self):
        """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
        sample_config = {
            "deepseek_api_key": "your_deepseek_api_key_here",
            "ai_base_url": "https://api.deepseek.com",
            "ai_model": "deepseek-chat",
            "check_interval_hours": 6,
            "max_videos_per_check": 5,
            "subtitle_languages": ["zh", "en"],
            "channels": [
                {
                    "name": "ç¤ºä¾‹é¢‘é“",
                    "channel_url": "https://www.youtube.com/@channelname",
                    "description": "é¢‘é“æè¿°"
                }
            ]
        }
        
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(sample_config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "check_interval_hours": 6,
            "max_videos_per_check": 5,
            "subtitle_languages": ["zh", "en"],
            "channels": []
        }

    def _build_subtitle_config(self) -> Dict:
        """åˆå¹¶æ—§ç‰ˆé…ç½®å­—æ®µä¸æ–°ç‰ˆå­—å¹•é…ç½®"""
        base = {
            "enabled": self.config.get("enable_subtitle_extraction", True),
            "languages": self.config.get("subtitle_languages", ["zh", "en"]),
            "allow_automatic_subtitles": self.config.get("allow_automatic_subtitles", True),
            "prefer_manual_subtitles": self.config.get("prefer_manual_subtitles", True),
            "max_retries": self.config.get("subtitle_max_retries", 3),
            "retry_wait_seconds": self.config.get("subtitle_retry_delay", 5),
            "request_timeout": self.config.get("subtitle_request_timeout", 30),
            "cookie_file": self.config.get("subtitle_cookie_file"),
            "proxy": self.config.get("subtitle_proxy"),
            "use_transcript_api": self.config.get("use_transcript_api", True),
            "transcript_api_auto_translate_to": self.config.get("transcript_api_auto_translate_to"),
            "transcript_api_preferred_languages": self.config.get(
                "transcript_api_preferred_languages", self.config.get("subtitle_languages", ["zh", "en"])
            ),
        }
        extra = self.config.get("subtitle_options", {})
        if isinstance(extra, dict):
            base.update({k: v for k, v in extra.items() if v is not None})
        return base
    
    def add_channel_from_url(self, name: str, channel_url: str, description: str = ""):
        """ä»URLæ·»åŠ é¢‘é“"""
        channel_id = self.rss_parser.get_channel_id_from_url(channel_url)
        if not channel_id:
            logging.error(f"æ— æ³•ä»URLè·å–é¢‘é“ID: {channel_url}")
            return False
        
        rss_url = self.rss_parser.get_rss_url(channel_id)
        
        channel = YouTubeChannel(
            name=name,
            channel_id=channel_id,
            rss_url=rss_url,
            description=description,
            last_check=datetime.now().isoformat()
        )
        
        self.db_manager.save_channel(channel)
        logging.info(f"å·²æ·»åŠ é¢‘é“: {name} ({channel_id})")
        return True
    
    def is_new_video(self, video: VideoInfo, channel_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ–°è§†é¢‘
        
        é€»è¾‘ï¼š
        1. å…¨æ–°é¢‘é“ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰ï¼šè¯¥é¢‘é“æ²¡æœ‰ä»»ä½•è§†é¢‘è®°å½•
        2. å·²æœ‰é¢‘é“ï¼šæ£€æŸ¥è§†é¢‘æ˜¯å¦æ¯”æ•°æ®åº“ä¸­æœ€æ–°çš„è§†é¢‘æ›´æ–°
        """
        # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨è¯¥è§†é¢‘
        if self.db_manager.video_exists(video.video_id):
            return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè¯¥é¢‘é“çš„é¦–æ¬¡è¿è¡Œ
        if self.db_manager.is_channel_first_run(channel_name):
            return True  # å…¨æ–°é¢‘é“ï¼Œæ‰€æœ‰è§†é¢‘éƒ½ç®—æ–°è§†é¢‘
        
        # å·²æœ‰é¢‘é“ï¼šæ£€æŸ¥æ˜¯å¦æ¯”æœ€æ–°è§†é¢‘æ›´æ–°
        latest_video_published_at = self.db_manager.get_latest_video_published_at_for_channel(channel_name)
        if not latest_video_published_at:
            return True  # å¦‚æœè·å–ä¸åˆ°æœ€æ–°è§†é¢‘å‘å¸ƒæ—¶é—´ï¼Œè®¤ä¸ºæ˜¯æ–°è§†é¢‘
        
        # æ¯”è¾ƒå‘å¸ƒæ—¶é—´ï¼Œåªæœ‰æ¯”æ•°æ®åº“ä¸­æœ€æ–°è§†é¢‘æ›´æ–°çš„æ‰ç®—æ–°è§†é¢‘
        try:
            from datetime import datetime
            video_time = datetime.fromisoformat(video.published_at.replace('Z', '+00:00'))
            latest_time = datetime.fromisoformat(latest_video_published_at.replace('Z', '+00:00'))
            return video_time > latest_time
        except Exception as e:
            logging.error(f"æ¯”è¾ƒè§†é¢‘å‘å¸ƒæ—¶é—´å¤±è´¥: {e}")
            return False  # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ï¼Œä¸è®¤ä¸ºæ˜¯æ–°è§†é¢‘
    
    def get_videos_to_process_for_channel(self, videos: List[VideoInfo], channel_name: str) -> List[VideoInfo]:
        """æ ¹æ®é¢‘é“çŠ¶æ€å†³å®šè¦å¤„ç†çš„è§†é¢‘
        
        é€»è¾‘ï¼š
        1. å…¨æ–°é¢‘é“ï¼šåªè¿”å›æœ€æ–°çš„1ä¸ªè§†é¢‘
        2. å·²æœ‰é¢‘é“ï¼šè¿”å›æ‰€æœ‰æ–°è§†é¢‘ï¼ˆå‘å¸ƒæ—¶é—´æ¯”æ•°æ®åº“ä¸­æœ€æ–°è§†é¢‘æ›´æ–°çš„è§†é¢‘ï¼‰
        """
        if not videos:
            return []
        
        # æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        try:
            sorted_videos = sorted(videos, key=lambda v: v.published_at, reverse=True)
        except Exception as e:
            logging.error(f"æ’åºè§†é¢‘å¤±è´¥: {e}")
            sorted_videos = videos
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè¯¥é¢‘é“çš„é¦–æ¬¡è¿è¡Œ
        if self.db_manager.is_channel_first_run(channel_name):
            # å…¨æ–°é¢‘é“ï¼šåªè¿”å›æœ€æ–°çš„1ä¸ªè§†é¢‘
            return [sorted_videos[0]]
        else:
            # å·²æœ‰é¢‘é“ï¼šè¿”å›æ‰€æœ‰æ–°è§†é¢‘ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼Œä½†é™åˆ¶æ•°é‡é¿å…è¿‡å¤šè¯·æ±‚ï¼‰
            new_videos = []
            max_videos = self.config.get('max_videos_per_check', 5)
            
            for video in sorted_videos:
                if len(new_videos) >= max_videos:
                    break
                if self.is_new_video(video, channel_name):
                    new_videos.append(video)
            
            # æŒ‰å‘å¸ƒæ—¶é—´æ­£åºæ’åˆ—ï¼ˆæ—§çš„åœ¨å‰ï¼Œæ–°çš„åœ¨åï¼‰ï¼Œè¿™æ ·å¤„ç†é¡ºåºæ›´åˆç†
            new_videos.sort(key=lambda v: v.published_at)
            return new_videos

    def check_updates(self) -> List[VideoInfo]:
        """æ£€æŸ¥æ‰€æœ‰é¢‘é“çš„æ›´æ–°
        
        é€»è¾‘ï¼š
        1. å…¨æ–°é¢‘é“ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰ï¼šæ¯ä¸ªé¢‘é“åªå¤„ç†æœ€æ–°çš„1ä¸ªè§†é¢‘
        2. å·²æœ‰é¢‘é“ï¼ˆåç»­è¿è¡Œï¼‰ï¼šæ£€æŸ¥æ¯”ç¼“å­˜æ›´æ–°çš„æ‰€æœ‰æ–°è§†é¢‘
        """
        all_new_videos = []
        
        for i, channel_config in enumerate(self.config.get('channels', [])):
            try:
                # æ·»åŠ é¢‘é“é—´éš”ï¼Œé¿å…è§¦å‘åçˆ¬è™«æœºåˆ¶
                if i > 0:  # ç¬¬ä¸€ä¸ªé¢‘é“ä¸éœ€è¦ç­‰å¾…
                    time.sleep(5)  # æ¯ä¸ªé¢‘é“ä¹‹é—´ç­‰å¾…5ç§’
                
                # è·³è¿‡æ²¡æœ‰é…ç½®channel_idä¸”channel_urlä¸ºç©ºçš„é¢‘é“
                if not channel_config.get('channel_id') and not channel_config.get('channel_url'):
                    logging.info(f"è·³è¿‡æœªé…ç½®çš„é¢‘é“: {channel_config['name']}")
                    continue
                
                # ä¼˜å…ˆä½¿ç”¨channel_idï¼Œå¦åˆ™ä»URLè·å–
                channel_id = channel_config.get('channel_id')
                if not channel_id:
                    channel_id = self.rss_parser.get_channel_id_from_url(channel_config['channel_url'])
                    if not channel_id:
                        logging.error(f"æ— æ³•è·å–é¢‘é“ID: {channel_config['channel_url']}")
                        continue
                
                # è·å–æˆ–åˆ›å»ºé¢‘é“è®°å½•
                channel = self.db_manager.get_channel(channel_id)
                if not channel:
                    rss_url = self.rss_parser.get_rss_url(channel_id)
                    channel = YouTubeChannel(
                        name=channel_config['name'],
                        channel_id=channel_id,
                        rss_url=rss_url,
                        description=channel_config.get('description', '')
                    )
                
                logging.info(f"æ£€æŸ¥é¢‘é“: {channel.name}")
                
                # è§£æRSSè®¢é˜…
                videos = self.rss_parser.parse_rss_feed(channel.rss_url)
                if not videos:
                    logging.info(f"é¢‘é“ {channel.name} æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
                    continue
                
                # æ ¹æ®é¢‘é“çŠ¶æ€å†³å®šè¦å¤„ç†çš„è§†é¢‘
                videos_to_process = self.get_videos_to_process_for_channel(videos, channel.name)
                
                if videos_to_process:
                    is_first_run = self.db_manager.is_channel_first_run(channel.name)
                    if is_first_run:
                        logging.info(f"å…¨æ–°é¢‘é“ {channel.name}ï¼Œå¤„ç†æœ€æ–°è§†é¢‘: {videos_to_process[0].title}")
                    else:
                        logging.info(f"é¢‘é“ {channel.name} å‘ç° {len(videos_to_process)} ä¸ªæ–°è§†é¢‘")
                else:
                    logging.info(f"é¢‘é“ {channel.name} æ²¡æœ‰æ–°è§†é¢‘")
                
                # å¤„ç†è§†é¢‘ï¼ˆæå–å­—å¹•å’Œç”Ÿæˆæ‘˜è¦ï¼‰
                new_videos = []
                for i, video in enumerate(videos_to_process):
                    try:
                        # è®¾ç½®æ­£ç¡®çš„é¢‘é“åç§°ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„åç§°ï¼‰
                        video.channel_name = channel.name
                        
                        # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œé¿å…è§¦å‘åçˆ¬è™«æœºåˆ¶
                        if i > 0:  # ç¬¬ä¸€ä¸ªè§†é¢‘ä¸éœ€è¦ç­‰å¾…
                            time.sleep(5)  # æ¯ä¸ªè§†é¢‘ä¹‹é—´ç­‰å¾…5ç§’
                        
                        # æå–å­—å¹•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if YT_DLP_AVAILABLE and self.config.get('enable_subtitle_extraction', True):
                            # åœ¨å­—å¹•æå–å‰å¢åŠ å»¶æ—¶
                            subtitle_delay = self.config.get('subtitle_request_delay', 5)
                            logging.info(f"ç­‰å¾…{subtitle_delay}ç§’åå¼€å§‹å­—å¹•æå–: {video.title}")
                            time.sleep(subtitle_delay)
                            
                            video.transcript = self.transcript_extractor.extract_transcript(
                                video.video_id,
                                self.subtitle_config.get('languages', ['zh', 'en'])
                            )
                            
                            # å¦‚æœå­—å¹•æå–å¤±è´¥ï¼Œå†ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•ä¸€æ¬¡
                            if not video.transcript:
                                retry_delay = self.config.get('subtitle_retry_delay', 10)
                                logging.info(f"é¦–æ¬¡å­—å¹•æå–å¤±è´¥ï¼Œç­‰å¾…{retry_delay}ç§’åé‡è¯•: {video.title}")
                                time.sleep(retry_delay)
                                video.transcript = self.transcript_extractor.extract_transcript(
                                video.video_id,
                                self.subtitle_config.get('languages', ['zh', 'en'])
                            )
                        else:
                            logging.info(f"å­—å¹•æå–å·²ç¦ç”¨ï¼Œè·³è¿‡: {video.title}")
                        
                        # ç”ŸæˆAIæ‘˜è¦ï¼ˆåªæœ‰åœ¨æœ‰å­—å¹•çš„æƒ…å†µä¸‹ï¼‰
                        if self.ai_processor and video.transcript:
                            ai_result = self.ai_processor.generate_summary_and_outline(
                                video.title, video.transcript
                            )
                            video.summary = ai_result['summary']
                            video.outline = ai_result['outline']
                        
                        # ä¿å­˜åˆ°æ•°æ®åº“
                        self.db_manager.save_video(video)
                        new_videos.append(video)
                        
                        logging.info(f"å¤„ç†å®Œæˆè§†é¢‘: {video.title}")
                        
                    except Exception as e:
                        logging.error(f"å¤„ç†è§†é¢‘å¤±è´¥ {video.title}: {e}")
                        continue
                
                # æ›´æ–°é¢‘é“ä¿¡æ¯
                if new_videos:
                    channel.last_video_id = new_videos[0].video_id
                    channel.last_update = datetime.now().isoformat()
                
                channel.last_check = datetime.now().isoformat()
                self.db_manager.save_channel(channel)
                
                all_new_videos.extend(new_videos)
                
            except Exception as e:
                logging.error(f"æ£€æŸ¥é¢‘é“æ›´æ–°å¤±è´¥: {e}")
                continue
        
        return all_new_videos
    
    def format_updates(self, videos: List[VideoInfo]) -> str:
        """æ ¼å¼åŒ–æ›´æ–°ä¿¡æ¯"""
        if not videos:
            return "æ²¡æœ‰å‘ç°æ–°è§†é¢‘"
        
        output = []
        output.append("=" * 50)
        output.append(f"YouTubeé¢‘é“æ›´æ–°æŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output.append("=" * 50)
        output.append(f"å‘ç° {len(videos)} ä¸ªæ–°è§†é¢‘")
        output.append("")
        
        for i, video in enumerate(videos, 1):
            output.append(f"ã€è§†é¢‘ {i}ã€‘")
            output.append(f"æ ‡é¢˜: {video.title}")
            output.append(f"é¢‘é“: {video.channel_name}")
            output.append(f"å‘å¸ƒæ—¶é—´: {video.published_at}")
            output.append(f"é“¾æ¥: {video.video_url}")
            output.append("")
            
            if video.description:
                output.append("è§†é¢‘æè¿°:")
                output.append(video.description[:200] + "..." if len(video.description) > 200 else video.description)
                output.append("")
            
            if video.transcript:
                output.append("å­—å¹•å†…å®¹:")
                output.append(video.transcript[:500] + "..." if len(video.transcript) > 500 else video.transcript)
                output.append("")
            
            if video.summary:
                output.append("AIæ‘˜è¦:")
                output.append(video.summary)
                output.append("")
            
            if video.outline:
                output.append("å†…å®¹å¤§çº²:")
                output.append(video.outline)
                output.append("")
            
            output.append("-" * 30)
            output.append("")
        
        return "\n".join(output)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('youtube_rss_monitor.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    try:
        # åˆå§‹åŒ–ç›‘æ§å™¨
        monitor = YouTubeRSSMonitor()
        
        # æ£€æŸ¥æ›´æ–°
        logging.info("å¼€å§‹æ£€æŸ¥YouTubeé¢‘é“æ›´æ–°...")
        new_videos = monitor.check_updates()
        
        # æ ¼å¼åŒ–å¹¶ä¿å­˜ç»“æœ
        formatted_updates = monitor.format_updates(new_videos)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"youtube_rss_updates_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(formatted_updates)
        
        logging.info(f"æ›´æ–°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        print(formatted_updates)
        
        # å‘é€é’‰é’‰é€šçŸ¥
        if new_videos and monitor.dingtalk_notifier:
            try:
                dingtalk_config = monitor.config.get('dingtalk', {})
                success = monitor.dingtalk_notifier.send_message(
                    videos=new_videos,
                    at_all=dingtalk_config.get('at_all', False),
                    at_mobiles=dingtalk_config.get('at_mobiles', [])
                )
                if success:
                    logging.info("é’‰é’‰é€šçŸ¥å‘é€æˆåŠŸ")
                else:
                    logging.warning("é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥")
            except Exception as e:
                logging.error(f"å‘é€é’‰é’‰é€šçŸ¥æ—¶å‡ºé”™: {e}")
        elif new_videos:
            logging.info("æœ‰æ–°è§†é¢‘ä½†é’‰é’‰æ¨é€æœªé…ç½®")
        else:
            logging.info("æ²¡æœ‰æ–°è§†é¢‘ï¼Œè·³è¿‡é’‰é’‰æ¨é€")
        
    except Exception as e:
        logging.error(f"ç¨‹åºè¿è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()
